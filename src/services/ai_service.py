"""
AI æœå‹™æ¨¡çµ„
è™•ç†æ‰€æœ‰ AI ç›¸é—œåŠŸèƒ½ï¼ŒåŒ…æ‹¬ Gemini API èª¿ç”¨ç­‰
"""
import os
import streamlit as st
import google.generativeai as genai
from src.core.config import TRANSCRIPT_FILENAME
from src.utils.file_manager import FileManager


class AIService:
    """AI æœå‹™ç®¡ç†å™¨"""
    
    @staticmethod
    def call_gemini_api(prompt, api_key, output_filename):
        """èª¿ç”¨ Google Gemini API"""
        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            response = model.generate_content(prompt)
            if not response.parts:
                block_reason = response.prompt_feedback.block_reason if response.prompt_feedback else "æœªçŸ¥"
                st.error(f"âŒ Gemini æ¨¡å‹å› æ•…æœªç”Ÿæˆä»»ä½•å…§å®¹ã€‚åŸå› : {block_reason}")
                return False

            with open(output_filename, "w", encoding="utf-8") as f:
                f.write(response.text)
            st.success(f"âœ… å ±å‘Šå·²æˆåŠŸç”± Gemini ç”Ÿæˆä¸¦å„²å­˜ç‚º {output_filename}")
            return True
        except Exception as e:
            st.error(f"âŒ Gemini API å‘¼å«å¤±æ•—: {e}")
            return False
    
    @staticmethod
    def refine_with_ai(report_output_filename, api_key, custom_prompt=None):
        """ä½¿ç”¨ AI ç”Ÿæˆå ±å‘Š"""
        st.write("ğŸ¤– æ­¥é©Ÿ 4/6: é–‹å§‹ä½¿ç”¨ AI æ½¤é£¾å ±å‘Š...")
        
        if not api_key:
            st.error("âŒ è«‹æä¾› API Keyã€‚")
            return False

        try:
            # ä½¿ç”¨è‡ªå®šç¾© prompt æˆ–é è¨­çš„ prompt æª”æ¡ˆ
            if custom_prompt:
                prompt_template = custom_prompt
                st.info("ğŸ¯ ä½¿ç”¨è‡ªå®šç¾© Prompt é€²è¡Œåˆ†æ")
            else:
                # å‘å¾Œå…¼å®¹ï¼šä½¿ç”¨ prompt.txt æª”æ¡ˆ
                prompt_file = "prompt.txt"
                if not os.path.exists(prompt_file):
                    st.warning(f"âš ï¸ æ‰¾ä¸åˆ° {prompt_file} æª”æ¡ˆï¼Œæ­£åœ¨å»ºç«‹ç©ºæª”æ¡ˆ...")
                    if not FileManager.create_empty_prompt_file(prompt_file):
                        return False
                
                with open(prompt_file, "r", encoding="utf-8") as f:
                    prompt_template = f.read()
                
                if not prompt_template.strip():
                    st.error("âŒ prompt.txt æª”æ¡ˆç‚ºç©ºã€‚")
                    return False
            
            with open(TRANSCRIPT_FILENAME, "r", encoding="utf-8") as f:
                transcript_text = f.read()

            if not transcript_text.strip():
                st.error("âŒ é€å­—ç¨¿ç‚ºç©ºï¼Œç„¡æ³•ç”¢ç”Ÿå ±å‘Šã€‚")
                return False

            # çµ„åˆæœ€çµ‚çš„ prompt
            if "{transcript_text}" in prompt_template:
                final_prompt = prompt_template.format(transcript_text=transcript_text)
            else:
                final_prompt = prompt_template + "\n\nå½±ç‰‡å…§å®¹é€å­—ç¨¿ï¼š\n" + transcript_text
            
            return AIService.call_gemini_api(final_prompt, api_key, report_output_filename)
                
        except Exception as e:
            st.error(f"âŒ AI API å‘¼å«å¤±æ•—: {e}")
            return False
