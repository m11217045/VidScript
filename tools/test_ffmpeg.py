"""
"""
æ¸¬è©¦ Faster-Whisper å’Œ FFmpeg é…ç½®
ç¢ºä¿ç³»çµ±èƒ½æ­£ç¢ºé‹è¡ŒèªéŸ³è½‰æ–‡å­—åŠŸèƒ½
"""
"""
import os
import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å°å…¥é…ç½®
from src.core.config import FFMPEG_PATH

def test_ffmpeg():
    """æ¸¬è©¦ FFmpeg æ˜¯å¦å¯ç”¨"""
    print("ğŸ”§ æ¸¬è©¦ FFmpeg é…ç½®...")
    print(f"FFmpeg è·¯å¾‘: {FFMPEG_PATH}")
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if os.path.exists(FFMPEG_PATH):
        print("âœ… FFmpeg æª”æ¡ˆå­˜åœ¨")
    else:
        print("âŒ FFmpeg æª”æ¡ˆä¸å­˜åœ¨")
        return False
    
    # æ¸¬è©¦åŸ·è¡Œ
    try:
        import subprocess
        result = subprocess.run([FFMPEG_PATH, "-version"], 
                               capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… FFmpeg å¯ä»¥æ­£å¸¸åŸ·è¡Œ")
            # é¡¯ç¤ºç‰ˆæœ¬è³‡è¨Šçš„ç¬¬ä¸€è¡Œ
            version_line = result.stdout.split('\n')[0]
            print(f"ç‰ˆæœ¬: {version_line}")
            return True
        else:
            print("âŒ FFmpeg åŸ·è¡Œå¤±æ•—")
            print(f"éŒ¯èª¤: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ æ¸¬è©¦ FFmpeg æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def test_faster_whisper_loading():
    """æ¸¬è©¦ Faster-Whisper çš„è¼‰å…¥åŠŸèƒ½"""
    print("\nğŸµ æ¸¬è©¦ Faster-Whisper è¼‰å…¥...")
    
    try:
        # è¨­å®š FFmpeg è·¯å¾‘åˆ°ç’°å¢ƒè®Šæ•¸
        internal_dir = os.path.dirname(FFMPEG_PATH)
        original_path = os.environ.get('PATH', '')
        if internal_dir not in original_path:
            os.environ['PATH'] = f"{internal_dir};{original_path}"
            print(f"âœ… å·²è¨­å®š FFmpeg è·¯å¾‘åˆ° PATH: {internal_dir}")
        
        # å˜—è©¦å°å…¥ faster-whisper
        from faster_whisper import WhisperModel
        print("âœ… Faster-Whisper æ¨¡çµ„å°å…¥æˆåŠŸ")
        
        # æ¸¬è©¦æ¨¡å‹åˆå§‹åŒ–ï¼ˆä½¿ç”¨æœ€å°çš„ tiny æ¨¡å‹ï¼‰
        try:
            # æª¢æŸ¥æ˜¯å¦æœ‰ CUDA
            try:
                import torch
                cuda_available = torch.cuda.is_available()
                device = "cuda" if cuda_available else "cpu"
                compute_type = "float16" if cuda_available else "int8"
                print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {device}, ç²¾åº¦: {compute_type}")
            except ImportError:
                device = "cpu"
                compute_type = "int8"
                print("ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: CPU (PyTorch æœªå®‰è£)")
            
            # å˜—è©¦è¼‰å…¥ tiny æ¨¡å‹é€²è¡Œå¿«é€Ÿæ¸¬è©¦
            print("ğŸ”„ æ­£åœ¨æ¸¬è©¦æ¨¡å‹è¼‰å…¥ (tiny æ¨¡å‹)...")
            model = WhisperModel("tiny", device=device, compute_type=compute_type)
            print("âœ… Faster-Whisper æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            
            # æ¸…ç†è¨˜æ†¶é«”
            del model
            if device == "cuda":
                try:
                    torch.cuda.empty_cache()
                    print("ğŸ§¹ å·²æ¸…ç† GPU è¨˜æ†¶é«”")
                except:
                    pass
            
            return True
            
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹è¼‰å…¥æ¸¬è©¦å¤±æ•—ï¼Œä½†æ¨¡çµ„å°å…¥æˆåŠŸ: {e}")
            return True  # æ¨¡çµ„å°å…¥æˆåŠŸå°±ç®—é€šé
        
    except Exception as e:
        print(f"âŒ Faster-Whisper æ¸¬è©¦å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹ FFmpeg å’Œ Faster-Whisper é…ç½®æ¸¬è©¦...\n")
    
    ffmpeg_ok = test_ffmpeg()
    faster_whisper_ok = test_faster_whisper_loading()
    
    print(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
    print(f"FFmpeg: {'âœ… é€šé' if ffmpeg_ok else 'âŒ å¤±æ•—'}")
    print(f"Faster-Whisper: {'âœ… é€šé' if faster_whisper_ok else 'âŒ å¤±æ•—'}")
    
    if ffmpeg_ok and faster_whisper_ok:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼æ‚¨çš„ FFmpeg é…ç½®æ‡‰è©²æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("\nâš ï¸ æœ‰äº›æ¸¬è©¦å¤±æ•—ï¼Œå¯èƒ½éœ€è¦é€²ä¸€æ­¥æª¢æŸ¥é…ç½®ã€‚")
